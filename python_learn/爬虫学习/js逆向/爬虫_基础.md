#爬虫基础
##筛选器
###正则表达式
.*?()贪婪匹配，^表达匹配开始，$匹配结束
```cython
import re
```
re.match()
```cython
import re
content = """Xiaoshuaib has 100
bananas"""
res = re.match('^Xi.*?(\d+)\s.*s$',content,re.S)
print(res.group(1))
```
re.search(),返回匹配成功的第一个
```cython
import re
content = """Xiaoshuaib has 100
bananas"""
res = re.search('Xi.*?(\d+)\s.*s',content,re.S)
print(res.group(1))
```
re.findall(),获取所有,返回列表
```cython
import re
content = """Xiaoshuaib has 100 bananas;
Xiaoshuaib has 100 bananas;
Xiaoshuaib has 100 bananas;
Xiaoshuaib has 100 bananas;"""
res = re.findall('Xi.*?(\d+)\s.*?s;',content,re.S)
print(res)
```
re.sub(),将对象替换成其他字符
```cython
import re
content = """Xiaoshuaib has 100 bananas;
Xiaoshuaib has 100 bananas;
Xiaoshuaib has 100 bananas;
Xiaoshuaib has 100 bananas;"""
content = re.sub('\d+','250',content)
```

###beautifulsoup
find方法
```cython
from bs4 import BeautifulSoup
html=""
soup=BeautifulSoup(html,'lxml')
print(soup.title.string)
print(soup.p.string)
# 获取title的父级
print(soup.title.parent.name)
# 获取单个超链接
print(soup.a)
# 获取所有a超链接
print(soup.find_all('a'))
# 获取id为link2的超链接
print(soup.find(id="link2"))
# 获取网页中所有内容
print(soup.get_text())
```
基于css方面
```cython
from bs4 import BeautifulSoup
html_doc=""
soup = BeautifulSoup(html_doc,'lxml')
print(soup.select("title"))
print(soup.select("body a"))
print(soup.select("p > #link1"))
```
##ip轮换功能
```python
import requests
from requests_ip_rotator import ApiGateWay
# 创建实例ApiGateway
gateway = ApiGateway("https://example.com", randomize_headers=True)

```
###xPath
在xpath中，获取的值为列表，所以应该
```
from lxml import etree
        html = etree.HTML(response.text, etree.HTMLParser())
        # // *[ @ id = "content"] / div / div[1] / div[1] / div[2] / div[1] / div / ul[1]
        uls = html.xpath('//*[@id="content"]/div/div[1]/div[1]/div[2]/div[1]/div/ul')
        for ul in uls:
            lis = ul.xpath('./li')
            for li in lis:
                name = li.xpath('./div[2]/div[1]/a/text()')[0]
                href=li.xpath('./div[2]/div[1]/a/@href')[0]
                print([name,href])


```
##情形分析
###数据传输以json形式传送
json.dumps():将 python 对象转化为 json
json.loads():将json数据转化为python对象
```cython
import json
jsondata = '''
{
"Uin":0,
"UserName":"@c482d142bc698bc3971d9f8c26335c5c",
"NickName":"小帅b",
}
'''
myfriend = json.loads(jsondata)
myfriend.get('NickName')
```